Parsec/Lexer«import«Lang/RegExp¸ Parsec/Input»¸ type«data«Token«s»¸ Token«s¸ String»»¸ data«Lexer«s»¸ Lexer«[«Token«s»»¸ RegExp»»»¸ define«newLexer«->«[«Token«s»»¸ Lexer«s»»¸ ->«tokens¸ do«let«matcher¸ @join«@map«tokens¸ ->>«token¸ i¸ do«let«Token«_¸ re»¸ token»¸ _concat«[«"(?<g"¸ _show«i»¸ ">"¸ re¸ ")"»»»»»¸ "|"»»¸ Lexer«tokens¸ _reflags«matcher¸ "yu"»»»»»¸ matchToken«->«Lexer«s»¸ String¸ Number¸ ?«Token«s»»»¸ ->«Lexer«tokens¸ matcher»¸ input¸ pos¸ do«RegExp:«.lastIndex.set«matcher¸ pos»»¸ match«RegExp:«.exec«matcher¸ input»»¸ |«?«m»¸ @first«tokens¸ ->>«token¸ i¸ match«:get«RegExpExecArray:«.groups«m»»¸ ##«"g"¸ _show«i»»»¸ |«?«s»¸ do«let«Token«t¸ _»¸ token»¸ ?«Token«t¸ s»»»»¸ |«_¸ Null»»»»»¸ |«_¸ Null»»»»»¸ lexerInput«->«String¸ Lexer«a»¸ Token«a»¸ ParserInput«Token«a»»»¸ ->«input¸ lexer¸ eof¸ do«set«pos¸ -1»¸ set«curr¸ eof»¸ let«tokens¸ [»¸ let«next¸ \«do«let«len¸ match«@«tokens¸ ^«pos»»¸ |«Token«_¸ text»¸ _strLen«text»»¸ |«_¸ 1»»»¸ if«<«+«^«pos»¸ len»¸ _strLen«input»»¸ do«:=«pos¸ +«^«pos»¸ len»»¸ let«mat¸ match«@«tokens¸ ^«pos»»¸ |«tok¸ ?«tok»»¸ |«_¸ matchToken«lexer¸ input¸ ^«pos»»»»»¸ match«mat¸ |«?«tok»¸ do«@set«tokens¸ ^«pos»¸ tok»¸ :=«curr¸ tok»»»¸ |«_¸ throw«"Invalid token"»»»»¸ eof»»»»¸ {«position«\«^«pos»»»¸ next«next»¸ current«\«^«curr»»»»»»»»»